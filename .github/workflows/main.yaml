name: Ahri pipeline

on:
  push:
    branches: [ main, ci ]

jobs:
  dataset:
    runs-on: ubuntu-22.04

    env:
#      DATASET_URL: https://90victor09.ru/aiarch/News_Category_Dataset.json.zip
#      DATASET_URL: https://90victor09.ru/aiarch/News_Category_Dataset_v2.json.zip
      DATASET_URL: https://90victor09.ru/aiarch/News_Category_Dataset_v3.json.zip

    steps:
      - name: cache source data
        id: cache-source-data
        uses: actions/cache@v3
        with:
          path: dataset.json
          key: source-dataset-${{ env.DATASET_URL }}

      - name: download source data
        if: steps.cache-source-data.outputs.cache-hit != 'true'
        run: |
          sudo apt-get install -y wget unzip
          wget -O dataset.zip $DATASET_URL
          unzip -p dataset.zip >dataset.json
          rm dataset.zip

      - name: Save source dataset
        uses: actions/upload-artifact@v3
        with:
          name: source-dataset
          path: ./dataset.json

  save-data:
    runs-on: ubuntu-22.04
    container:
      image: ghcr.io/90victor09/ahri/base:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.github_token }}
    needs: dataset
    environment: ahri

    steps:
      - uses: actions/checkout@v3

      - name: Download source dataset
        uses: actions/download-artifact@v3
        with:
          name: source-dataset
          path: ./

      - name: Prepare data
        run: |
          ln -s /root/nltk_data /github/home/nltk_data 
          ./prepare-data.py ./dataset.json ./output.json

      - name: Upload data
        env:
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_PORT: ${{ secrets.DB_PORT }}
          DB_DB: ${{ secrets.DB_DB }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASS: ${{ secrets.DB_PASS }}
        run: |
          ./save-data.py ./output.json

  train-models:
    runs-on: ubuntu-22.04
    container:
      image: ghcr.io/90victor09/ahri/base:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.github_token }}
    needs: save-data
    environment: ahri

    strategy:
      fail-fast: false
      matrix:
        model:
          - tfidf.SVCModel tfidf_svc
          - tfidf.MultinomialNBModel tfidf_nb
          - |
            tfidf.DecisionTreeClassifierModel tfidf_dt 0 '{"DecisionTreeClassifier__random_state": 42, "DecisionTreeClassifier__min_samples_leaf": 30}'
          - |
            tfidf.OneVsRestSVCModel tfidf_ovr_svc
#          - |
#            tfidf.KNNModel tfidf_knn 0 '{"KNN__n_neighbors": 41}'
#          - |
#            tfidf.RandomForestModel tfidf_rf 0 '{"RandomForestClassifier__random_state": 42, "RandomForestClassifier__verbose": true}'
    steps:
      - uses: actions/checkout@v3

      - name: Train model ${{ matrix.model }}
        env:
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_PORT: ${{ secrets.DB_PORT }}
          DB_DB: ${{ secrets.DB_DB }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASS: ${{ secrets.DB_PASS }}
        run: |
          ./train-model.py ${{ matrix.model }}

  select-model:
    runs-on: ubuntu-22.04

    env:
      MODELS: >-
        tfidf_svc
        tfidf_nb
        tfidf_dt
        tfidf_ovr_svc

    container:
      image: ghcr.io/90victor09/ahri/base:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.github_token }}
    needs: train-models
    environment: ahri

    steps:
      - uses: actions/checkout@v3

      - name: Select model
        env:
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_PORT: ${{ secrets.DB_PORT }}
          DB_DB: ${{ secrets.DB_DB }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASS: ${{ secrets.DB_PASS }}
        run: |
          ./select-model.py ${{ env.MODELS }} | tee /tmp/selection.out

      - name: Deploy model
        env:
          APP_API_BASE: ${{ secrets.APP_API_BASE }}
          APP_API_KEY: ${{ secrets.APP_API_KEY }}
        run: |
          MODEL=$(cat /tmp/selection.out | tail -n1 | grep -oP "Best model: \K(.+)$")
          ./deploy-model.py $MODEL
